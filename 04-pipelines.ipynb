{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c636111-00ef-4406-ae06-e32b2ab76e14",
   "metadata": {},
   "source": [
    "## Creating Pipelines\n",
    "\n",
    "In notebooks [2](02-feature-engineering.ipynb) and  [3](03-model-logistic-regression.ipynb) we developed and trained a feature engineering technique and a logistic regression model. In this notebook we will combine them into a pipeline. \n",
    "\n",
    "Machine learning pipelines allow you to precisely specify a set of transformations which start with raw data and result in a model. They make it possible to re-train the same model repeatedly, using different parameter values, and to reapply these same transformations to raw data in production, resulting in predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bf0fd-3bcf-4242-b9fb-91c6a9de0345",
   "metadata": {},
   "source": [
    "We load in our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe01dcb3-24d2-43bb-9a18-b4dedaeee3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"fraud-cleaned-sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f4eee0-b29c-45a0-ab25-2fcb42341e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train, test = model_selection.train_test_split(df, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b47dd-cc9e-49f3-bcde-e18d44d935d4",
   "metadata": {},
   "source": [
    "Now we load the pipeline steps we created in earier notebooks. These are `feat_pipeline.pkl` and `lr.pkl`, corresponding to the feature engineering stages and the logisitc regression model, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba6b96c-d83f-46fa-8a69-81c1acc1a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as cp\n",
    "feature_pipeline = cp.load(open('feat_pipeline.pkl', 'rb'))\n",
    "model = cp.load(open('lr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0bb9e-bdca-48b1-b193-0b25ec99d656",
   "metadata": {},
   "source": [
    "Now we can combine these stages together in a pipeline and fit it to training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f864be-9819-4710-b8d1-2bef78c959ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', feature_pipeline),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a40f2de-e981-42c6-8b41-74a8e99d1fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 Pipeline(steps=[('feature_extraction',\n",
       "                                  ColumnTransformer(transformers=[('interarrival_scaler',\n",
       "                                                                   Pipeline(steps=[('median_imputer',\n",
       "                                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                                   ('interarrival_scaler',\n",
       "                                                                                    RobustScaler())]),\n",
       "                                                                   ['interarrival']),\n",
       "                                                                  ('amount_scaler',\n",
       "                                                                   RobustScaler(),\n",
       "                                                                   ['amount']),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(categories=[['online',\n",
       "                                                                                              'contactless',\n",
       "                                                                                              'chip_and_pin',\n",
       "                                                                                              'manual',\n",
       "                                                                                              'swipe']],\n",
       "                                                                                 handle_unknown='ignore'),\n",
       "                                                                   ['trans_type']),\n",
       "                                                                  ('m_hashing',\n",
       "                                                                   Pipeline(steps=[('dictify',\n",
       "                                                                                    FunctionTransformer(accept_sparse=True,\n",
       "                                                                                                        func=<function amap at 0x7f2df59fddc0>)),\n",
       "                                                                                   ('hasher',\n",
       "                                                                                    FeatureHasher(n_features=256))]),\n",
       "                                                                   'merchant_id')]))])),\n",
       "                ('model', LogisticRegression(max_iter=500))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b748dc3-9a8a-43cc-9f42-7f5f412ba534",
   "metadata": {},
   "source": [
    "Here you can see all the transformations and parameters used in the pipeline. \n",
    "\n",
    "We can refit the whole pipeline to training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696bc76b-8204-452d-bf82-98bd15348b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 Pipeline(steps=[('feature_extraction',\n",
       "                                  ColumnTransformer(transformers=[('interarrival_scaler',\n",
       "                                                                   Pipeline(steps=[('median_imputer',\n",
       "                                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                                   ('interarrival_scaler',\n",
       "                                                                                    RobustScaler())]),\n",
       "                                                                   ['interarrival']),\n",
       "                                                                  ('amount_scaler',\n",
       "                                                                   RobustScaler(),\n",
       "                                                                   ['amount']),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(categories=[['online',\n",
       "                                                                                              'contactless',\n",
       "                                                                                              'chip_and_pin',\n",
       "                                                                                              'manual',\n",
       "                                                                                              'swipe']],\n",
       "                                                                                 handle_unknown='ignore'),\n",
       "                                                                   ['trans_type']),\n",
       "                                                                  ('m_hashing',\n",
       "                                                                   Pipeline(steps=[('dictify',\n",
       "                                                                                    FunctionTransformer(accept_sparse=True,\n",
       "                                                                                                        func=<function amap at 0x7f2df59fddc0>)),\n",
       "                                                                                   ('hasher',\n",
       "                                                                                    FeatureHasher(n_features=256))]),\n",
       "                                                                   'merchant_id')]))])),\n",
       "                ('model', LogisticRegression(max_iter=500))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train, y = train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6548c-1da9-4cfd-a078-31bcf0156479",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can use this pipeline to make predictions - let's predict for our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d7d3cb-c526-4eb2-bb0c-a27acebfa4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['legitimate', 'legitimate', 'legitimate', ..., 'legitimate',\n",
       "       'legitimate', 'legitimate'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2702d-4176-445c-b20a-88f40cdaed8f",
   "metadata": {},
   "source": [
    "Let's now save this pipeline as one pickled object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb58752-8879-45be-9c85-f708f272b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.dump(pipeline, open(\"pipeline.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494cc4a-4771-4212-9bbc-5d1c6e6fc696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
